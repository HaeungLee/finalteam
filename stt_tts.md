# STT/TTS í†µí•© êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

Agentica í”„ë¡œì íŠ¸ì— ìŒì„± ì¸ì‹(STT: Speech-to-Text)ê³¼ ìŒì„± í•©ì„±(TTS: Text-to-Speech) ê¸°ëŠ¥ì„ í†µí•©í•˜ê¸° ìœ„í•œ ì„¤ê³„ ë¬¸ì„œì…ë‹ˆë‹¤.

## ğŸ¯ ëª©í‘œ

- **í•œêµ­ì–´ ìµœì í™”**: í•œêµ­ì–´ ìŒì„± ì²˜ë¦¬ì— íŠ¹í™”ëœ ì„¤ê³„
- **Clean Architecture**: ê¸°ì¡´ Agentica Controller íŒ¨í„´ê³¼ í˜¸í™˜
- **Multi-Provider**: ì—¬ëŸ¬ ìŒì„± ì„œë¹„ìŠ¤ ì œê³µì ì§€ì›
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: WebRTC ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”
- **ì„±ëŠ¥ ìµœì í™”**: ìµœì†Œí•œì˜ ì˜ì¡´ì„±ìœ¼ë¡œ ê³ ì„±ëŠ¥ êµ¬í˜„

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1. í™˜ê²½ë³€ìˆ˜ í™•ì¥

```typescript
// SGlobal.ts í™•ì¥
interface IEnvironments {
  // ...existing code...
  
  // TTS/STT ì„¤ì •
  TTS_PROVIDER?: "openai" | "google" | "azure" | "elevenlabs" | "naver";
  STT_PROVIDER?: "openai" | "google" | "azure" | "naver";
  
  // API í‚¤
  ELEVENLABS_API_KEY?: string;
  AZURE_SPEECH_KEY?: string;
  AZURE_SPEECH_REGION?: string;
  NAVER_CLOVA_CLIENT_ID?: string;
  NAVER_CLOVA_CLIENT_SECRET?: string;
  
  // ìŒì„± ì„¤ì •
  TTS_VOICE_ID?: string;
  TTS_LANGUAGE?: "ko-KR" | "en-US";
  STT_LANGUAGE?: "ko-KR" | "en-US";
  TTS_SPEED?: string; // "0.5" ~ "2.0"
  TTS_PITCH?: string; // "-20" ~ "+20"
}
```

### 2. í´ë” êµ¬ì¡°

```
test-agentica/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceWrapperService.ts      # ë©”ì¸ ìŒì„± ì„œë¹„ìŠ¤
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ IVoiceService.ts        # ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ OpenAIVoiceService.ts   # OpenAI êµ¬í˜„
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ GoogleVoiceService.ts   # Google Cloud êµ¬í˜„
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ NaverVoiceService.ts    # Naver Clova êµ¬í˜„
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ElevenLabsVoiceService.ts # ElevenLabs êµ¬í˜„
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ AzureVoiceService.ts    # Azure Cognitive êµ¬í˜„
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AudioConverter.ts       # ì˜¤ë””ì˜¤ í¬ë§· ë³€í™˜
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ KoreanOptimizer.ts      # í•œêµ­ì–´ ìµœì í™”
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ AudioValidator.ts       # ì˜¤ë””ì˜¤ ê²€ì¦
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ TTSOptions.ts           # TTS ì˜µì…˜ íƒ€ì…
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ STTOptions.ts           # STT ì˜µì…˜ íƒ€ì…
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ VoiceResponse.ts        # ì‘ë‹µ íƒ€ì…
â”‚   â”‚   â”‚   â””â”€â”€ ...existing services...
â”‚   â”‚   â””â”€â”€ ...existing code...
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceChat.tsx               # ìŒì„± ì±„íŒ… ì»´í¬ë„ŒíŠ¸
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AudioRecorder.tsx           # ìŒì„± ë…¹ìŒê¸°
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AudioPlayer.tsx             # ìŒì„± ì¬ìƒê¸°
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ VoiceSettings.tsx           # ìŒì„± ì„¤ì •
â”‚   â”‚   â”‚   â””â”€â”€ ...existing components...
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceChat.ts                 # ìŒì„± ì±„íŒ… í›…
â”‚   â”‚   â”‚   â”œâ”€â”€ useAudioRecorder.ts             # ë…¹ìŒ í›…
â”‚   â”‚   â”‚   â””â”€â”€ useAudioPlayer.ts               # ì¬ìƒ í›…
â”‚   â”‚   â””â”€â”€ ...existing code...
â””â”€â”€ stt_tts.md                                  # ì´ ë¬¸ì„œ
```

## ğŸ”§ í•µì‹¬ êµ¬í˜„

### 1. Voice Service ì¸í„°í˜ì´ìŠ¤

```typescript
export interface IVoiceService {
  /**
   * í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
   */
  textToSpeech(text: string, options?: TTSOptions): Promise<VoiceBuffer>;
  
  /**
   * ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
   */
  speechToText(audioBuffer: Buffer, options?: STTOptions): Promise<STTResult>;
  
  /**
   * ì§€ì›í•˜ëŠ” ìŒì„± ëª©ë¡ ì¡°íšŒ
   */
  getAvailableVoices(): Promise<VoiceInfo[]>;
  
  /**
   * ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
   */
  healthCheck(): Promise<boolean>;
}

export interface TTSOptions {
  voice?: string;           // ìŒì„± ID
  language?: string;        // ì–¸ì–´ ì½”ë“œ (ko-KR, en-US)
  speed?: number;           // ì†ë„ (0.25 ~ 4.0)
  pitch?: number;           // í†¤ (-20 ~ +20)
  format?: 'mp3' | 'wav';   // ì¶œë ¥ í¬ë§·
}

export interface STTOptions {
  language?: string;        // ì–¸ì–´ ì½”ë“œ
  model?: string;           // ëª¨ë¸ëª…
  enablePunctuation?: boolean; // êµ¬ë‘ì  ìë™ ì‚½ì…
  enableProfanityFilter?: boolean; // ìš•ì„¤ í•„í„°
}
```

### 2. í•œêµ­ì–´ ìµœì í™” ìœ í‹¸ë¦¬í‹°

```typescript
export class KoreanOptimizer {
  /**
   * í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (TTSìš©)
   */
  static preprocessTextForTTS(text: string): string {
    return text
      .replace(/([0-9]+)/g, (match) => this.numberToKorean(match))
      .replace(/([A-Za-z]+)/g, (match) => this.englishToKoreanPronunciation(match))
      .replace(/\s+/g, ' ')
      .trim();
  }
  
  /**
   * í•œêµ­ì–´ ìŒì„± ì¸ì‹ í›„ì²˜ë¦¬ (STTìš©)
   */
  static postprocessSTTResult(text: string): string {
    return text
      .replace(/\s+/g, ' ')
      .replace(/([ê°€-í£])\s+([ê°€-í£])/g, '$1$2') // í•œê¸€ ë‹¨ì–´ ì—°ê²°
      .trim();
  }
  
  /**
   * ìˆ«ìë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜
   */
  private static numberToKorean(num: string): string {
    // êµ¬í˜„: "123" â†’ "ë°±ì´ì‹­ì‚¼"
    // ...
  }
  
  /**
   * ì˜ì–´ë¥¼ í•œêµ­ì–´ ë°œìŒìœ¼ë¡œ ë³€í™˜
   */
  private static englishToKoreanPronunciation(eng: string): string {
    // êµ¬í˜„: "OpenAI" â†’ "ì˜¤í”ˆì—ì´ì•„ì´"
    // ...
  }
}
```

### 3. Voice Wrapper Service

```typescript
export class VoiceWrapperService {
  private readonly ttsService: IVoiceService;
  private readonly sttService: IVoiceService;
  
  constructor(props: {
    ttsProvider: string;
    sttProvider: string;
    apiKeys: Record<string, string>;
  }) {
    this.ttsService = this.createVoiceService(props.ttsProvider, props.apiKeys);
    this.sttService = this.createVoiceService(props.sttProvider, props.apiKeys);
  }
  
  /**
   * AI ì‘ë‹µì„ í•œêµ­ì–´ ìŒì„±ìœ¼ë¡œ ë³€í™˜
   */
  async convertToSpeech(input: {
    /**
     * ë³€í™˜í•  í…ìŠ¤íŠ¸
     * @title í…ìŠ¤íŠ¸
     */
    text: string;
    
    /**
     * ìŒì„± ì„¤ì •
     * @title ìŒì„±
     */
    voice?: string;
    
    /**
     * ì–¸ì–´ ì„¤ì • (ê¸°ë³¸: ko-KR)
     * @title ì–¸ì–´
     */
    language?: "ko-KR" | "en-US";
    
    /**
     * ìŒì„± ì†ë„ (ê¸°ë³¸: 1.0)
     * @title ì†ë„
     */
    speed?: number;
    
    /**
     * í•œêµ­ì–´ ìµœì í™” ì ìš© ì—¬ë¶€ (ê¸°ë³¸: true)
     * @title í•œêµ­ì–´ ìµœì í™”
     */
    optimizeKorean?: boolean;
  }) {
    console.log('ğŸ”Š TTS ë³€í™˜ ìš”ì²­:', { text: input.text.substring(0, 50) + '...' });
    
    // í•œêµ­ì–´ ìµœì í™”
    let processedText = input.text;
    if (input.optimizeKorean !== false && input.language === 'ko-KR') {
      processedText = KoreanOptimizer.preprocessTextForTTS(input.text);
    }
    
    const audioBuffer = await this.ttsService.textToSpeech(processedText, {
      voice: input.voice || this.getDefaultKoreanVoice(),
      language: input.language || "ko-KR",
      speed: input.speed || 1.0,
      format: 'mp3',
    });
    
    return {
      audio: audioBuffer.data.toString('base64'),
      format: audioBuffer.format,
      duration: this.estimateDuration(input.text),
      language: input.language || "ko-KR",
    };
  }
  
  /**
   * ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (í•œêµ­ì–´ ìµœì í™”)
   */
  async convertToText(input: {
    /**
     * ìŒì„± ë°ì´í„° (Base64 ë˜ëŠ” Buffer)
     * @title ìŒì„± ë°ì´í„°
     */
    audioData: string | Buffer;
    
    /**
     * ì–¸ì–´ ì„¤ì • (ê¸°ë³¸: ko-KR)
     * @title ì–¸ì–´
     */
    language?: "ko-KR" | "en-US";
    
    /**
     * êµ¬ë‘ì  ìë™ ì‚½ì… (ê¸°ë³¸: true)
     * @title êµ¬ë‘ì  ì‚½ì…
     */
    enablePunctuation?: boolean;
    
    /**
     * í•œêµ­ì–´ í›„ì²˜ë¦¬ ì ìš© ì—¬ë¶€ (ê¸°ë³¸: true)
     * @title í•œêµ­ì–´ í›„ì²˜ë¦¬
     */
    postprocessKorean?: boolean;
  }) {
    console.log('ğŸ¤ STT ë³€í™˜ ìš”ì²­');
    
    const audioBuffer = typeof input.audioData === 'string' 
      ? Buffer.from(input.audioData, 'base64')
      : input.audioData;
    
    const result = await this.sttService.speechToText(audioBuffer, {
      language: input.language || "ko-KR",
      enablePunctuation: input.enablePunctuation !== false,
    });
    
    // í•œêµ­ì–´ í›„ì²˜ë¦¬
    let processedText = result.text;
    if (input.postprocessKorean !== false && input.language === 'ko-KR') {
      processedText = KoreanOptimizer.postprocessSTTResult(result.text);
    }
    
    return {
      text: processedText,
      confidence: result.confidence,
      language: input.language || "ko-KR",
      duration: result.duration,
    };
  }
  
  /**
   * ê¸°ë³¸ í•œêµ­ì–´ ìŒì„± ë°˜í™˜
   */
  private getDefaultKoreanVoice(): string {
    // Providerë³„ ê¸°ë³¸ í•œêµ­ì–´ ìŒì„± ì„¤ì •
    if (this.ttsService instanceof NaverVoiceService) {
      return 'nara'; // ë„¤ì´ë²„ í´ë¡œë°” ë‚˜ë¼ ìŒì„±
    } else if (this.ttsService instanceof GoogleVoiceService) {
      return 'ko-KR-Standard-A'; // êµ¬ê¸€ í•œêµ­ì–´ ìŒì„±
    } else {
      return 'alloy'; // OpenAI ê¸°ë³¸ ìŒì„±
    }
  }
}
```

## ğŸŒŸ ì£¼ìš” íŠ¹ì§•

### 1. í•œêµ­ì–´ íŠ¹í™” ê¸°ëŠ¥

- **ìˆ«ì ë°œìŒ ìµœì í™”**: "123" â†’ "ë°±ì´ì‹­ì‚¼"
- **ì˜ì–´ ë‹¨ì–´ í•œêµ­ì–´ ë°œìŒ**: "OpenAI" â†’ "ì˜¤í”ˆì—ì´ì•„ì´"
- **í•œêµ­ì–´ ë¬¸ì¥ ì—°ê²° ìµœì í™”**: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ìŒì„± ìƒì„±
- **í•œêµ­ì–´ ìŒì„± ì¸ì‹ í›„ì²˜ë¦¬**: ë„ì–´ì“°ê¸° ë° ë§ì¶¤ë²• ë³´ì •

### 2. Multi-Provider ì§€ì›

| Provider | TTS ì§€ì› | STT ì§€ì› | í•œêµ­ì–´ í’ˆì§ˆ | ë¹„ìš© |
|----------|----------|----------|-------------|------|
| OpenAI   | âœ…       | âœ…       | â­â­â­      | ğŸ’°ğŸ’°  |
| Google   | âœ…       | âœ…       | â­â­â­â­    | ğŸ’°ğŸ’°ğŸ’° |
| Naver    | âœ…       | âœ…       | â­â­â­â­â­  | ğŸ’°    |
| Azure    | âœ…       | âœ…       | â­â­â­â­    | ğŸ’°ğŸ’°  |
| ElevenLabs | âœ…     | âŒ       | â­â­â­      | ğŸ’°ğŸ’°ğŸ’° |

### 3. ì„±ëŠ¥ ìµœì í™”

- **Streaming TTS**: ê¸´ í…ìŠ¤íŠ¸ì˜ ì‹¤ì‹œê°„ ìŒì„± ìƒì„±
- **Audio Compression**: íš¨ìœ¨ì ì¸ ì˜¤ë””ì˜¤ ì••ì¶•
- **Caching**: ìì£¼ ì‚¬ìš©ë˜ëŠ” ìŒì„± ìºì‹±
- **Batch Processing**: ì—¬ëŸ¬ ìš”ì²­ ì¼ê´„ ì²˜ë¦¬

## ğŸš€ êµ¬í˜„ ë‹¨ê³„

### Phase 1: ê¸°ë³¸ TTS/STT (1ì£¼)
- [ ] OpenAI TTS/STT êµ¬í˜„
- [ ] VoiceWrapperService ê¸°ë³¸ êµ¬ì¡°
- [ ] í™˜ê²½ë³€ìˆ˜ ì„¤ì •
- [ ] ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‘ì„±

### Phase 2: í•œêµ­ì–´ ìµœì í™” (1ì£¼)
- [ ] KoreanOptimizer êµ¬í˜„
- [ ] Naver Clova ì—°ë™
- [ ] í•œêµ­ì–´ íŠ¹í™” ì „/í›„ì²˜ë¦¬
- [ ] í•œêµ­ì–´ í’ˆì§ˆ í…ŒìŠ¤íŠ¸

### Phase 3: í´ë¼ì´ì–¸íŠ¸ í†µí•© (1ì£¼)
- [ ] React ìŒì„± ì»´í¬ë„ŒíŠ¸
- [ ] WebRTC ì‹¤ì‹œê°„ ìŒì„±
- [ ] ìŒì„± ì„¤ì • UI
- [ ] ì‚¬ìš©ì ê²½í—˜ ìµœì í™”

### Phase 4: ê³ ê¸‰ ê¸°ëŠ¥ (1ì£¼)
- [ ] ê°ì • ì¸ì‹ ë° TTS í†¤ ì¡°ì ˆ
- [ ] ë‹¤í™”ì ì¸ì‹
- [ ] ë…¸ì´ì¦ˆ ìº”ìŠ¬ë§
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

## ğŸ“Š í…ŒìŠ¤íŠ¸ ì „ëµ

### 1. TDD í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```typescript
describe('VoiceWrapperService', () => {
  describe('convertToSpeech', () => {
    it('í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜¬ë°”ë¥´ê²Œ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•¨', async () => {
      // Given
      const service = new VoiceWrapperService(config);
      const input = { text: 'ì•ˆë…•í•˜ì„¸ìš”', language: 'ko-KR' };
      
      // When
      const result = await service.convertToSpeech(input);
      
      // Then
      expect(result.audio).toBeDefined();
      expect(result.format).toBe('mp3');
      expect(result.language).toBe('ko-KR');
    });
  });
  
  describe('convertToText', () => {
    it('í•œêµ­ì–´ ìŒì„±ì„ ì˜¬ë°”ë¥´ê²Œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì•¼ í•¨', async () => {
      // Given
      const service = new VoiceWrapperService(config);
      const audioBuffer = generateKoreanAudioSample();
      
      // When
      const result = await service.convertToText({ audioData: audioBuffer });
      
      // Then
      expect(result.text).toContain('ì•ˆë…•í•˜ì„¸ìš”');
      expect(result.confidence).toBeGreaterThan(0.8);
    });
  });
});
```

### 2. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

- **ì‘ë‹µ ì‹œê°„**: TTS/STT ë³€í™˜ ì†ë„ ì¸¡ì •
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ëŒ€ìš©ëŸ‰ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- **ë™ì‹œ ì²˜ë¦¬**: ë‹¤ì¤‘ ìš”ì²­ ì²˜ë¦¬ ì„±ëŠ¥
- **í•œêµ­ì–´ í’ˆì§ˆ**: í•œêµ­ì–´ ìŒì„± í’ˆì§ˆ í‰ê°€

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### 1. Agentì—ì„œ ìŒì„± ì‘ë‹µ

```typescript
// ì‚¬ìš©ì: "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?"
// Agent ì²˜ë¦¬ í›„ ìŒì„±ìœ¼ë¡œ ì‘ë‹µ
const weatherResponse = "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ” ë§‘ê³  ê¸°ì˜¨ì€ 25ë„ì…ë‹ˆë‹¤.";
const voiceResponse = await voiceService.convertToSpeech({
  text: weatherResponse,
  language: "ko-KR",
  optimizeKorean: true
});

// í´ë¼ì´ì–¸íŠ¸ë¡œ ìŒì„± ë°ì´í„° ì „ì†¡
await websocket.send({
  type: 'voice_response',
  data: voiceResponse
});
```

### 2. ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”

```typescript
// í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìŒì„± ë…¹ìŒ
const audioBlob = await recorder.stop();

// STTë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
const sttResult = await voiceService.convertToText({
  audioData: audioBlob,
  language: "ko-KR"
});

// Agent ì²˜ë¦¬
const agentResponse = await agent.conversate(sttResult.text);

// TTSë¡œ ìŒì„± ì‘ë‹µ ìƒì„±
const ttsResult = await voiceService.convertToSpeech({
  text: agentResponse,
  language: "ko-KR"
});

// ìŒì„± ì¬ìƒ
await audioPlayer.play(ttsResult.audio);
```

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

- **API í‚¤ ë³´í˜¸**: í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•œ ì•ˆì „í•œ í‚¤ ê´€ë¦¬
- **ì˜¤ë””ì˜¤ ë°ì´í„° ì•”í˜¸í™”**: ì „ì†¡ ì¤‘ ì˜¤ë””ì˜¤ ë°ì´í„° ë³´í˜¸
- **ì‚¬ìš©ëŸ‰ ì œí•œ**: ë¬´ì œí•œ ìŒì„± ë³€í™˜ ë°©ì§€
- **ê°œì¸ì •ë³´ ë³´í˜¸**: ìŒì„± ë°ì´í„° ì„ì‹œ ì €ì¥ í›„ ì‚­ì œ

## ğŸ“š ì°¸ê³  ìë£Œ

- [OpenAI Speech API](https://platform.openai.com/docs/guides/text-to-speech)
- [Google Cloud Speech-to-Text](https://cloud.google.com/speech-to-text)
- [Naver Clova Voice](https://www.ncloud.com/product/aiService/css)
- [WebRTC Audio Processing](https://webrtc.org/)
- [í•œêµ­ì–´ ìŒì„±í•™ ê¸°ì´ˆ](https://www.korean.go.kr/)

## ğŸ¯ ì˜ˆìƒ íš¨ê³¼

- **ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ**: ìŒì„± ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ AI ëŒ€í™”
- **ì ‘ê·¼ì„± ê°œì„ **: ì‹œê° ì¥ì• ì¸ ë° ê±°ë™ ë¶ˆí¸í•œ ì‚¬ìš©ì ì§€ì›
- **íš¨ìœ¨ì„± ì¦ëŒ€**: íƒ€ì´í•‘ ì—†ì´ ë¹ ë¥¸ ì •ë³´ ì…ë ¥/ì¶œë ¥
- **í•œêµ­ì–´ íŠ¹í™”**: í•œêµ­ ì‚¬ìš©ìì—ê²Œ ìµœì í™”ëœ ìŒì„± ê²½í—˜

---

**ì‘ì„±ì¼**: 2025ë…„ 6ì›” 14ì¼  
**ë²„ì „**: 1.0  
**ì‘ì„±ì**: Agentica Development Team
